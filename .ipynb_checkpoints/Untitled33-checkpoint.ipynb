{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.genfromtxt('diabetes.csv',delimiter=',', skip_header=1) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Glucose=data[:,1]\n",
    "Glucose.reshape(-1, 1)\n",
    "Glucose.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes=data[:,8]\n",
    "###diabetes.reshape(-1,1)\n",
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sk.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[148.  85. 183.  89. 137. 116.  78. 115. 197. 125. 110. 168. 139. 189.\n 166. 100. 118. 107. 103. 115. 126.  99. 196. 119. 143. 125. 147.  97.\n 145. 117. 109. 158.  88.  92. 122. 103. 138. 102.  90. 111. 180. 133.\n 106. 171. 159. 180. 146.  71. 103. 105. 103. 101.  88. 176. 150.  73.\n 187. 100. 146. 105.  84. 133.  44. 141. 114.  99. 109. 109.  95. 146.\n 100. 139. 126. 129.  79.   0.  62.  95. 131. 112. 113.  74.  83. 101.\n 137. 110. 106. 100. 136. 107.  80. 123.  81. 134. 142. 144.  92.  71.\n  93. 122. 163. 151. 125.  81.  85. 126.  96. 144.  83.  95. 171. 155.\n  89.  76. 160. 146. 124.  78.  97.  99. 162. 111. 107. 132. 113.  88.\n 120. 118. 117. 105. 173. 122. 170.  84.  96. 125. 100.  93. 129. 105.\n 128. 106. 108. 108. 154. 102.  57. 106. 147.  90. 136. 114. 156. 153.\n 188. 152.  99. 109.  88. 163. 151. 102. 114. 100. 131. 104. 148. 120.\n 110. 111. 102. 134.  87.  79.  75. 179.  85. 129. 143. 130.  87. 119.\n   0.  73. 141. 194. 181. 128. 109. 139. 111. 123. 159. 135.  85. 158.\n 105. 107. 109. 148. 113. 138. 108.  99. 103. 111. 196. 162.  96. 184.\n  81. 147. 179. 140. 112. 151. 109. 125.  85. 112. 177. 158. 119. 142.\n 100.  87. 101. 162. 197. 117. 142. 134.  79. 122.  74. 171. 181. 179.\n 164. 104.  91.  91. 139. 119. 146. 184. 122. 165. 124. 111. 106. 129.\n  90.  86.  92. 113. 111. 114. 193. 155. 191. 141.  95. 142. 123.  96.\n 138. 128. 102. 146. 101. 108. 122.  71. 106. 100. 106. 104. 114. 108.\n 146. 129. 133. 161. 108. 136. 155. 119.  96. 108.  78. 107. 128. 128.\n 161. 151. 146. 126. 100. 112. 167. 144.  77. 115. 150. 120. 161. 137.\n 128. 124.  80. 106. 155. 113. 109. 112.  99. 182. 115. 194. 129. 112.\n 124. 152. 112. 157. 122. 179. 102. 105. 118.  87. 180. 106.  95. 165.\n 117. 115. 152. 178. 130.  95.   0. 122.  95. 126. 139. 116.  99.   0.\n  92. 137.  61.  90.  90. 165. 125. 129.  88. 196. 189. 158. 103. 146.\n 147.  99. 124. 101.  81. 133. 173. 118.  84. 105. 122. 140.  98.  87.\n 156.  93. 107. 105. 109.  90. 125. 119. 116. 105. 144. 100. 100. 166.\n 131. 116. 158. 127.  96. 131.  82. 193.  95. 137. 136.  72. 168. 123.\n 115. 101. 197. 172. 102. 112. 143. 143. 138. 173.  97. 144.  83. 129.\n 119.  94. 102. 115. 151. 184.  94. 181. 135.  95.  99.  89.  80. 139.\n  90. 141. 140. 147.  97. 107. 189.  83. 117. 108. 117. 180. 100.  95.\n 104. 120.  82. 134.  91. 119. 100. 175. 135.  86. 148. 134. 120.  71.\n  74.  88. 115. 124.  74.  97. 120. 154. 144. 137. 119. 136. 114. 137.\n 105. 114. 126. 132. 158. 123.  85.  84. 145. 135. 139. 173.  99. 194.\n  83.  89.  99. 125.  80. 166. 110.  81. 195. 154. 117.  84.   0.  94.\n  96.  75. 180. 130.  84. 120.  84. 139.  91.  91.  99. 163. 145. 125.\n  76. 129.  68. 124. 114. 130. 125.  87.  97. 116. 117. 111. 122. 107.\n  86.  91.  77. 132. 105.  57. 127. 129. 100. 128.  90.  84.  88. 186.\n 187. 131. 164. 189. 116.  84. 114.  88.  84. 124.  97. 110. 103.  85.\n 125. 198.  87.  99.  91.  95.  99.  92. 154. 121.  78. 130. 111.  98.\n 143. 119. 108. 118. 133. 197. 151. 109. 121. 100. 124.  93. 143. 103.\n 176.  73. 111. 112. 132.  82. 123. 188.  67.  89. 173. 109. 108.  96.\n 124. 150. 183. 124. 181.  92. 152. 111. 106. 174. 168. 105. 138. 106.\n 117.  68. 112. 119. 112.  92. 183.  94. 108.  90. 125. 132. 128.  94.\n 114. 102. 111. 128.  92. 104. 104.  94.  97. 100. 102. 128. 147.  90.\n 103. 157. 167. 179. 136. 107.  91. 117. 123. 120. 106. 155. 101. 120.\n 127.  80. 162. 199. 167. 145. 115. 112. 145. 111.  98. 154. 165.  99.\n  68. 123.  91. 195. 156.  93. 121. 101.  56. 162.  95. 125. 136. 129.\n 130. 107. 140. 144. 107. 158. 121. 129.  90. 142. 169.  99. 127. 118.\n 122. 125. 168. 129. 110.  80. 115. 127. 164.  93. 158. 126. 129. 134.\n 102. 187. 173.  94. 108.  97.  83. 114. 149. 117. 111. 112. 116. 141.\n 175.  92. 130. 120. 174. 106. 105.  95. 126.  65.  99. 102. 120. 102.\n 109. 140. 153. 100. 147.  81. 187. 162. 136. 121. 108. 181. 154. 128.\n 137. 123. 106. 190.  88. 170.  89. 101. 122. 121. 126.  93.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2cada321fb8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlucose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiabetes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1532\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[148.  85. 183.  89. 137. 116.  78. 115. 197. 125. 110. 168. 139. 189.\n 166. 100. 118. 107. 103. 115. 126.  99. 196. 119. 143. 125. 147.  97.\n 145. 117. 109. 158.  88.  92. 122. 103. 138. 102.  90. 111. 180. 133.\n 106. 171. 159. 180. 146.  71. 103. 105. 103. 101.  88. 176. 150.  73.\n 187. 100. 146. 105.  84. 133.  44. 141. 114.  99. 109. 109.  95. 146.\n 100. 139. 126. 129.  79.   0.  62.  95. 131. 112. 113.  74.  83. 101.\n 137. 110. 106. 100. 136. 107.  80. 123.  81. 134. 142. 144.  92.  71.\n  93. 122. 163. 151. 125.  81.  85. 126.  96. 144.  83.  95. 171. 155.\n  89.  76. 160. 146. 124.  78.  97.  99. 162. 111. 107. 132. 113.  88.\n 120. 118. 117. 105. 173. 122. 170.  84.  96. 125. 100.  93. 129. 105.\n 128. 106. 108. 108. 154. 102.  57. 106. 147.  90. 136. 114. 156. 153.\n 188. 152.  99. 109.  88. 163. 151. 102. 114. 100. 131. 104. 148. 120.\n 110. 111. 102. 134.  87.  79.  75. 179.  85. 129. 143. 130.  87. 119.\n   0.  73. 141. 194. 181. 128. 109. 139. 111. 123. 159. 135.  85. 158.\n 105. 107. 109. 148. 113. 138. 108.  99. 103. 111. 196. 162.  96. 184.\n  81. 147. 179. 140. 112. 151. 109. 125.  85. 112. 177. 158. 119. 142.\n 100.  87. 101. 162. 197. 117. 142. 134.  79. 122.  74. 171. 181. 179.\n 164. 104.  91.  91. 139. 119. 146. 184. 122. 165. 124. 111. 106. 129.\n  90.  86.  92. 113. 111. 114. 193. 155. 191. 141.  95. 142. 123.  96.\n 138. 128. 102. 146. 101. 108. 122.  71. 106. 100. 106. 104. 114. 108.\n 146. 129. 133. 161. 108. 136. 155. 119.  96. 108.  78. 107. 128. 128.\n 161. 151. 146. 126. 100. 112. 167. 144.  77. 115. 150. 120. 161. 137.\n 128. 124.  80. 106. 155. 113. 109. 112.  99. 182. 115. 194. 129. 112.\n 124. 152. 112. 157. 122. 179. 102. 105. 118.  87. 180. 106.  95. 165.\n 117. 115. 152. 178. 130.  95.   0. 122.  95. 126. 139. 116.  99.   0.\n  92. 137.  61.  90.  90. 165. 125. 129.  88. 196. 189. 158. 103. 146.\n 147.  99. 124. 101.  81. 133. 173. 118.  84. 105. 122. 140.  98.  87.\n 156.  93. 107. 105. 109.  90. 125. 119. 116. 105. 144. 100. 100. 166.\n 131. 116. 158. 127.  96. 131.  82. 193.  95. 137. 136.  72. 168. 123.\n 115. 101. 197. 172. 102. 112. 143. 143. 138. 173.  97. 144.  83. 129.\n 119.  94. 102. 115. 151. 184.  94. 181. 135.  95.  99.  89.  80. 139.\n  90. 141. 140. 147.  97. 107. 189.  83. 117. 108. 117. 180. 100.  95.\n 104. 120.  82. 134.  91. 119. 100. 175. 135.  86. 148. 134. 120.  71.\n  74.  88. 115. 124.  74.  97. 120. 154. 144. 137. 119. 136. 114. 137.\n 105. 114. 126. 132. 158. 123.  85.  84. 145. 135. 139. 173.  99. 194.\n  83.  89.  99. 125.  80. 166. 110.  81. 195. 154. 117.  84.   0.  94.\n  96.  75. 180. 130.  84. 120.  84. 139.  91.  91.  99. 163. 145. 125.\n  76. 129.  68. 124. 114. 130. 125.  87.  97. 116. 117. 111. 122. 107.\n  86.  91.  77. 132. 105.  57. 127. 129. 100. 128.  90.  84.  88. 186.\n 187. 131. 164. 189. 116.  84. 114.  88.  84. 124.  97. 110. 103.  85.\n 125. 198.  87.  99.  91.  95.  99.  92. 154. 121.  78. 130. 111.  98.\n 143. 119. 108. 118. 133. 197. 151. 109. 121. 100. 124.  93. 143. 103.\n 176.  73. 111. 112. 132.  82. 123. 188.  67.  89. 173. 109. 108.  96.\n 124. 150. 183. 124. 181.  92. 152. 111. 106. 174. 168. 105. 138. 106.\n 117.  68. 112. 119. 112.  92. 183.  94. 108.  90. 125. 132. 128.  94.\n 114. 102. 111. 128.  92. 104. 104.  94.  97. 100. 102. 128. 147.  90.\n 103. 157. 167. 179. 136. 107.  91. 117. 123. 120. 106. 155. 101. 120.\n 127.  80. 162. 199. 167. 145. 115. 112. 145. 111.  98. 154. 165.  99.\n  68. 123.  91. 195. 156.  93. 121. 101.  56. 162.  95. 125. 136. 129.\n 130. 107. 140. 144. 107. 158. 121. 129.  90. 142. 169.  99. 127. 118.\n 122. 125. 168. 129. 110.  80. 115. 127. 164.  93. 158. 126. 129. 134.\n 102. 187. 173.  94. 108.  97.  83. 114. 149. 117. 111. 112. 116. 141.\n 175.  92. 130. 120. 174. 106. 105.  95. 126.  65.  99. 102. 120. 102.\n 109. 140. 153. 100. 147.  81. 187. 162. 136. 121. 108. 181. 154. 128.\n 137. 123. 106. 190.  88. 170.  89. 101. 122. 121. 126.  93.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "logreg.fit(Glucose,diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
