{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.639, 0.099, 0.   ],\n",
       "       [0.025, 0.686, 0.   ],\n",
       "       [0.275, 0.544, 0.   ],\n",
       "       ...,\n",
       "       [0.55 , 0.062, 0.   ],\n",
       "       [0.455, 0.138, 0.   ],\n",
       "       [0.315, 0.207, 0.   ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Loading traindata from csv, read and display storing in trainData\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import os\n",
    "trainData = np.genfromtxt(\"/Users/panigrahirenuka/PythonPractice/JupyterNotebook/trainData.csv\", delimiter=\",\", skip_header=1)\n",
    "trainData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Separating the third off set in the  trainData numpy array by slicing it and giving name as trainLabels\n",
    "trainLabels= trainData[:,2]\n",
    "trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.099, 0.686, 0.544, 0.978, 0.359, 0.398, 0.19 , 0.122, 0.848,\n",
       "       0.455, 0.663, 0.642, 0.597, 0.021, 0.787, 0.244, 0.126, 0.565,\n",
       "       0.069, 0.765, 0.207, 0.216, 0.87 , 0.329, 0.148, 0.901, 0.003,\n",
       "       0.858, 0.145, 0.13 , 0.251, 0.174, 0.661, 0.026, 0.015, 0.79 ,\n",
       "       0.238, 0.324, 0.174, 0.052, 0.742, 0.526, 0.746, 0.476, 0.778,\n",
       "       0.513, 0.109, 0.504, 0.945, 0.043, 0.783, 0.867, 0.521, 0.458,\n",
       "       0.964, 0.061, 0.479, 0.402, 0.686, 0.49 , 0.91 , 0.073, 0.081,\n",
       "       0.608, 0.066, 0.275, 0.633, 0.548, 0.325, 0.995, 0.531, 0.454,\n",
       "       0.605, 0.099, 0.702, 0.853, 0.651, 0.769, 0.721, 0.215, 0.452,\n",
       "       0.228, 0.339, 0.453, 0.416, 0.095, 0.427, 0.665, 0.374, 0.153,\n",
       "       0.923, 0.067, 0.832, 0.093, 0.097, 0.739, 0.812, 0.556, 0.586,\n",
       "       0.562, 0.33 , 0.122, 0.354, 0.665, 0.75 , 0.868, 0.721, 0.968,\n",
       "       0.6  , 0.352, 0.578, 0.213, 0.657, 0.224, 0.108, 0.845, 0.368,\n",
       "       0.763, 0.574, 0.807, 0.845, 0.975, 0.818, 0.614, 0.643, 0.026,\n",
       "       0.929, 0.829, 0.267, 0.18 , 0.703, 0.309, 0.34 , 0.006, 0.87 ,\n",
       "       0.566, 0.401, 0.142, 0.633, 0.031, 0.746, 0.215, 0.42 , 0.341,\n",
       "       0.37 , 0.722, 0.777, 0.568, 0.085, 0.053, 0.157, 0.618, 0.674,\n",
       "       0.272, 0.662, 0.486, 0.442, 0.273, 0.755, 0.114, 0.43 , 0.283,\n",
       "       0.678, 0.487, 0.667, 0.045, 0.395, 0.599, 0.008, 0.301, 0.211,\n",
       "       0.137, 0.256, 0.328, 0.008, 0.747, 0.176, 0.38 , 0.704, 0.5  ,\n",
       "       0.833, 0.806, 0.072, 0.862, 0.042, 0.019, 0.921, 0.862, 0.576,\n",
       "       0.573, 0.709, 0.418, 0.115, 0.021, 0.325, 0.801, 0.618, 0.832,\n",
       "       0.92 , 0.088, 0.844, 0.243, 0.589, 0.524, 0.396, 0.31 , 0.34 ,\n",
       "       0.333, 0.168, 0.51 , 0.114, 0.51 , 0.906, 0.349, 0.727, 0.819,\n",
       "       0.815, 0.236, 0.146, 0.197, 0.602, 0.76 , 0.656, 0.177, 0.773,\n",
       "       0.494, 0.754, 0.76 , 0.449, 0.924, 0.564, 0.635, 0.625, 0.864,\n",
       "       0.627, 0.151, 0.068, 0.442, 0.303, 0.275, 0.056, 0.507, 0.31 ,\n",
       "       0.452, 0.057, 0.832, 0.077, 0.864, 0.855, 0.615, 0.507, 0.463,\n",
       "       0.554, 0.792, 0.896, 0.45 , 0.81 , 0.652, 0.322, 0.476, 0.151,\n",
       "       0.062, 0.104, 0.899, 0.343, 0.714, 0.505, 0.173, 0.248, 0.438,\n",
       "       0.439, 0.523, 0.159, 0.373, 0.283, 0.409, 0.338, 0.598, 0.789,\n",
       "       0.647, 0.066, 0.095, 0.678, 0.284, 0.724, 0.657, 0.906, 0.873,\n",
       "       0.333, 0.583, 0.141, 0.35 , 0.968, 0.698, 0.392, 0.595, 0.938,\n",
       "       0.31 , 0.377, 0.792, 0.813, 0.67 , 0.829, 0.739, 0.685, 0.526,\n",
       "       0.646, 0.423, 0.362, 0.363, 0.18 , 0.214, 0.948, 0.486, 0.227,\n",
       "       0.138, 0.077, 0.844, 0.101, 0.771, 0.835, 0.884, 0.038, 0.337,\n",
       "       0.766, 0.131, 0.377, 0.162, 0.831, 0.771, 0.809, 0.166, 0.438,\n",
       "       0.411, 0.676, 0.238, 0.444, 0.285, 0.749, 0.449, 0.534, 0.309,\n",
       "       0.809, 0.469, 0.835, 0.368, 0.947, 0.984, 0.462, 0.282, 0.382,\n",
       "       0.527, 0.966, 0.817, 0.801, 0.138, 0.25 , 0.641, 0.874, 0.555,\n",
       "       0.103, 0.846, 0.851, 0.285, 0.763, 0.273, 0.905, 0.147, 0.437,\n",
       "       0.946, 0.222, 0.451, 0.35 , 0.027, 0.053, 0.502, 0.236, 0.995,\n",
       "       0.375, 0.028, 0.931, 0.839, 0.65 , 0.791, 0.138, 0.287, 0.83 ,\n",
       "       0.696, 0.139, 0.706, 0.449, 0.005, 0.079, 0.256, 0.835, 0.549,\n",
       "       0.727, 0.528, 0.111, 0.288, 0.301, 0.048, 0.42 , 0.794, 0.457,\n",
       "       0.111, 0.905, 0.597, 0.016, 0.515, 0.242, 0.144, 0.429, 0.615,\n",
       "       0.241, 0.417, 0.664, 0.086, 0.975, 0.068, 0.526, 0.507, 0.988,\n",
       "       0.554, 0.39 , 0.47 , 0.636, 0.981, 0.254, 0.016, 0.789, 0.345,\n",
       "       0.733, 0.628, 0.772, 0.735, 0.333, 0.044, 0.546, 0.814, 0.175,\n",
       "       0.779, 0.465, 0.695, 0.632, 0.811, 0.063, 0.776, 0.458, 0.293,\n",
       "       0.044, 0.199, 0.042, 0.933, 0.515, 0.989, 0.543, 0.253, 0.753,\n",
       "       0.191, 0.357, 0.781, 0.866, 0.332, 0.124, 0.368, 0.889, 0.743,\n",
       "       0.895, 0.387, 0.974, 0.496, 0.498, 0.924, 0.519, 0.801, 0.727,\n",
       "       0.079, 0.602, 0.822, 0.545, 0.321, 0.08 , 0.661, 0.306, 0.603,\n",
       "       0.426, 0.69 , 0.352, 0.042, 0.87 , 0.353, 0.998, 0.275, 0.98 ,\n",
       "       0.948, 0.075, 0.638, 0.363, 0.801, 0.679, 0.953, 0.143, 0.608,\n",
       "       0.781, 0.035, 0.067, 0.779, 0.366, 0.383, 0.567, 0.605, 0.679,\n",
       "       0.949, 0.372, 0.763, 0.574, 0.529, 0.398, 0.65 , 0.25 , 0.113,\n",
       "       0.736, 0.499, 0.387, 0.562, 0.262, 0.26 , 0.446, 0.996, 0.286,\n",
       "       0.916, 0.491, 0.123, 0.853, 0.452, 0.899, 0.445, 0.088, 0.682,\n",
       "       0.846, 0.32 , 0.347, 0.065, 0.542, 0.891, 0.851, 0.712, 0.927,\n",
       "       0.638, 0.794, 0.509, 0.121, 0.201, 0.139, 0.79 , 0.026, 0.554,\n",
       "       0.369, 0.804, 0.552, 0.612, 0.086, 0.309, 1.   , 0.719, 0.526,\n",
       "       0.769, 0.823, 0.074, 0.972, 0.642, 0.45 , 0.68 , 0.345, 0.878,\n",
       "       0.78 , 0.64 , 0.182, 0.966, 0.433, 0.911, 0.055, 0.124, 0.153,\n",
       "       0.165, 0.323, 0.709, 0.346, 0.941, 0.895, 0.846, 0.251, 0.635,\n",
       "       0.551, 0.125, 0.303, 0.533, 0.503, 0.169, 0.942, 0.154, 0.659,\n",
       "       0.721, 0.605, 0.843, 0.564, 0.825, 0.028, 0.045, 0.641, 0.577,\n",
       "       0.651, 0.767, 0.417, 0.639, 0.498, 0.627, 0.29 , 0.957, 0.483,\n",
       "       0.805, 0.685, 0.297, 0.073, 0.06 , 0.44 , 0.484, 0.204, 0.607,\n",
       "       0.313, 0.718, 0.734, 0.861, 0.975, 0.131, 0.371, 0.562, 0.319,\n",
       "       0.466, 0.267, 0.248, 0.097, 0.29 , 0.384, 0.615, 0.248, 0.865,\n",
       "       0.16 , 0.327, 0.578, 0.313, 0.763, 0.498, 0.515, 0.499, 0.309,\n",
       "       0.023, 0.945, 0.505, 0.967, 0.215, 0.353, 0.051, 0.495, 0.882,\n",
       "       0.654, 0.471, 0.537, 0.847, 0.431, 0.882, 0.728, 0.764, 0.366,\n",
       "       0.401, 0.57 , 0.195, 0.553, 0.074, 0.504, 0.764, 0.28 , 0.989,\n",
       "       0.68 , 0.119, 0.975, 0.394, 0.795, 0.339, 0.939, 0.755, 0.199,\n",
       "       0.509, 0.5  , 0.045, 0.137, 0.333, 0.474, 0.457, 0.606, 0.516,\n",
       "       0.328, 0.613, 0.163, 0.991, 0.739, 0.299, 0.336, 0.828, 0.532,\n",
       "       0.709, 0.3  , 0.816, 0.368, 0.674, 0.98 , 0.584, 0.797, 0.725,\n",
       "       0.688, 0.027, 0.475, 0.967, 0.783, 0.776, 0.578, 0.721, 0.584,\n",
       "       0.171, 0.629, 0.62 , 0.841, 0.148, 0.681, 0.032, 0.948, 0.11 ,\n",
       "       0.019, 0.314, 0.151, 0.691, 0.41 , 0.775, 0.921, 0.873, 0.736,\n",
       "       0.062, 0.138, 0.207])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Storing the first two rows of the TrainData in trainFeatures by numpy array slicing\n",
    "trainFeatures= trainData[:,1]\n",
    "trainFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97 , 0.662, 1.   ],\n",
       "       [0.404, 0.525, 1.   ],\n",
       "       [0.515, 0.314, 1.   ],\n",
       "       [0.988, 0.173, 1.   ],\n",
       "       [0.658, 0.912, 1.   ],\n",
       "       [0.543, 0.342, 1.   ],\n",
       "       [0.413, 0.354, 1.   ],\n",
       "       [0.188, 0.772, 1.   ],\n",
       "       [0.362, 0.721, 1.   ],\n",
       "       [0.756, 0.643, 1.   ],\n",
       "       [0.625, 0.693, 1.   ],\n",
       "       [0.76 , 0.61 , 1.   ],\n",
       "       [0.204, 0.192, 0.   ],\n",
       "       [0.549, 0.247, 1.   ],\n",
       "       [0.928, 0.558, 1.   ],\n",
       "       [0.438, 0.225, 0.   ],\n",
       "       [0.698, 0.973, 1.   ],\n",
       "       [0.121, 0.298, 0.   ],\n",
       "       [0.973, 0.289, 1.   ],\n",
       "       [0.609, 0.207, 0.   ],\n",
       "       [0.239, 0.705, 1.   ],\n",
       "       [0.158, 0.317, 0.   ],\n",
       "       [0.551, 0.349, 1.   ],\n",
       "       [0.552, 0.934, 1.   ],\n",
       "       [0.093, 0.795, 0.   ],\n",
       "       [0.992, 0.273, 1.   ],\n",
       "       [0.913, 0.122, 1.   ],\n",
       "       [0.461, 0.677, 1.   ],\n",
       "       [0.117, 0.38 , 0.   ],\n",
       "       [0.832, 0.98 , 1.   ],\n",
       "       [0.498, 0.818, 1.   ],\n",
       "       [0.717, 0.955, 1.   ],\n",
       "       [0.509, 0.805, 1.   ],\n",
       "       [0.273, 0.29 , 0.   ],\n",
       "       [0.835, 0.288, 1.   ],\n",
       "       [0.98 , 0.714, 1.   ],\n",
       "       [0.244, 0.346, 0.   ],\n",
       "       [0.551, 0.442, 1.   ],\n",
       "       [0.384, 0.256, 0.   ],\n",
       "       [0.922, 0.479, 1.   ],\n",
       "       [0.508, 0.202, 0.   ],\n",
       "       [0.879, 0.539, 1.   ],\n",
       "       [0.864, 0.933, 1.   ],\n",
       "       [0.276, 0.696, 1.   ],\n",
       "       [0.79 , 0.137, 0.   ],\n",
       "       [0.415, 0.616, 1.   ],\n",
       "       [0.934, 0.587, 1.   ],\n",
       "       [0.508, 0.242, 1.   ],\n",
       "       [0.821, 0.67 , 1.   ],\n",
       "       [0.283, 0.531, 0.   ],\n",
       "       [0.299, 0.638, 1.   ],\n",
       "       [0.587, 0.052, 0.   ],\n",
       "       [0.999, 0.413, 1.   ],\n",
       "       [0.49 , 0.717, 1.   ],\n",
       "       [0.149, 0.101, 0.   ],\n",
       "       [0.539, 0.771, 1.   ],\n",
       "       [0.345, 0.005, 0.   ],\n",
       "       [0.552, 0.55 , 1.   ],\n",
       "       [0.543, 0.929, 1.   ],\n",
       "       [0.455, 0.407, 0.   ],\n",
       "       [0.322, 0.935, 1.   ],\n",
       "       [0.189, 0.878, 1.   ],\n",
       "       [0.697, 0.477, 1.   ],\n",
       "       [0.572, 0.199, 0.   ],\n",
       "       [0.234, 0.964, 1.   ],\n",
       "       [0.776, 0.321, 1.   ],\n",
       "       [0.044, 0.646, 0.   ],\n",
       "       [0.745, 0.908, 1.   ],\n",
       "       [0.705, 0.089, 0.   ],\n",
       "       [0.811, 0.574, 1.   ],\n",
       "       [0.386, 0.535, 1.   ],\n",
       "       [0.664, 0.723, 1.   ],\n",
       "       [0.821, 0.937, 1.   ],\n",
       "       [0.981, 0.913, 1.   ],\n",
       "       [0.495, 0.175, 0.   ],\n",
       "       [0.037, 0.882, 1.   ],\n",
       "       [0.502, 0.176, 0.   ],\n",
       "       [0.59 , 0.92 , 1.   ],\n",
       "       [0.87 , 0.997, 1.   ],\n",
       "       [0.874, 0.397, 1.   ],\n",
       "       [0.44 , 0.495, 1.   ],\n",
       "       [0.526, 0.937, 1.   ],\n",
       "       [0.457, 0.962, 1.   ],\n",
       "       [0.722, 0.926, 1.   ],\n",
       "       [0.41 , 0.877, 1.   ],\n",
       "       [0.655, 0.009, 0.   ],\n",
       "       [0.154, 0.568, 0.   ],\n",
       "       [0.469, 0.107, 0.   ],\n",
       "       [0.969, 0.983, 1.   ],\n",
       "       [0.339, 0.285, 0.   ],\n",
       "       [0.693, 0.989, 1.   ],\n",
       "       [0.65 , 0.543, 1.   ],\n",
       "       [0.852, 0.494, 1.   ],\n",
       "       [0.852, 0.939, 1.   ],\n",
       "       [0.859, 0.851, 1.   ],\n",
       "       [0.38 , 0.468, 0.   ],\n",
       "       [0.317, 0.193, 0.   ],\n",
       "       [0.719, 0.113, 0.   ],\n",
       "       [0.759, 0.162, 0.   ],\n",
       "       [0.872, 0.459, 1.   ],\n",
       "       [0.036, 0.257, 0.   ],\n",
       "       [0.068, 0.186, 0.   ],\n",
       "       [0.631, 0.737, 1.   ],\n",
       "       [0.921, 0.791, 1.   ],\n",
       "       [0.997, 0.568, 1.   ],\n",
       "       [0.747, 0.757, 1.   ],\n",
       "       [0.434, 0.175, 0.   ],\n",
       "       [0.098, 0.856, 1.   ],\n",
       "       [0.634, 0.897, 1.   ],\n",
       "       [0.873, 0.827, 1.   ],\n",
       "       [0.444, 0.515, 1.   ],\n",
       "       [0.694, 0.087, 0.   ],\n",
       "       [0.903, 0.669, 1.   ],\n",
       "       [0.046, 0.185, 0.   ],\n",
       "       [0.796, 0.141, 0.   ],\n",
       "       [0.293, 0.324, 0.   ],\n",
       "       [0.375, 0.248, 0.   ],\n",
       "       [0.146, 0.261, 0.   ],\n",
       "       [0.531, 0.236, 0.   ],\n",
       "       [0.566, 0.754, 1.   ],\n",
       "       [0.793, 0.954, 1.   ],\n",
       "       [0.17 , 0.302, 0.   ],\n",
       "       [0.079, 0.723, 0.   ],\n",
       "       [0.871, 0.011, 1.   ],\n",
       "       [0.62 , 0.654, 1.   ],\n",
       "       [0.241, 0.693, 1.   ],\n",
       "       [0.913, 0.062, 1.   ],\n",
       "       [0.143, 0.118, 0.   ],\n",
       "       [0.461, 0.307, 0.   ],\n",
       "       [0.254, 0.405, 0.   ],\n",
       "       [0.255, 0.503, 0.   ],\n",
       "       [0.009, 0.895, 1.   ],\n",
       "       [0.805, 0.704, 1.   ],\n",
       "       [0.901, 0.311, 1.   ],\n",
       "       [0.678, 0.117, 0.   ],\n",
       "       [0.158, 0.916, 1.   ],\n",
       "       [0.442, 0.295, 0.   ],\n",
       "       [0.346, 0.615, 1.   ],\n",
       "       [0.588, 0.219, 1.   ],\n",
       "       [0.639, 0.134, 0.   ],\n",
       "       [0.424, 0.153, 0.   ],\n",
       "       [0.25 , 0.748, 1.   ],\n",
       "       [0.845, 0.606, 1.   ],\n",
       "       [0.199, 0.416, 0.   ],\n",
       "       [0.385, 0.549, 1.   ],\n",
       "       [0.483, 0.471, 1.   ],\n",
       "       [0.237, 0.538, 1.   ],\n",
       "       [0.572, 0.664, 1.   ],\n",
       "       [0.575, 0.218, 1.   ],\n",
       "       [0.993, 0.247, 1.   ],\n",
       "       [0.295, 0.755, 1.   ],\n",
       "       [0.978, 0.873, 1.   ],\n",
       "       [0.658, 0.082, 0.   ],\n",
       "       [0.274, 0.447, 0.   ],\n",
       "       [0.566, 0.704, 1.   ],\n",
       "       [0.686, 0.078, 0.   ],\n",
       "       [0.745, 0.564, 1.   ],\n",
       "       [0.049, 0.062, 0.   ],\n",
       "       [0.606, 0.548, 1.   ],\n",
       "       [0.497, 0.505, 1.   ],\n",
       "       [0.904, 0.573, 1.   ],\n",
       "       [0.286, 0.15 , 0.   ],\n",
       "       [0.799, 0.328, 1.   ],\n",
       "       [0.607, 0.52 , 1.   ],\n",
       "       [0.352, 0.116, 0.   ],\n",
       "       [0.637, 0.205, 1.   ],\n",
       "       [0.621, 0.583, 1.   ],\n",
       "       [0.678, 0.091, 0.   ],\n",
       "       [0.721, 0.51 , 1.   ],\n",
       "       [0.659, 0.809, 1.   ],\n",
       "       [0.838, 0.453, 1.   ],\n",
       "       [0.628, 0.513, 1.   ],\n",
       "       [0.903, 0.457, 1.   ],\n",
       "       [0.646, 0.058, 0.   ],\n",
       "       [0.309, 0.462, 1.   ],\n",
       "       [0.441, 0.807, 1.   ],\n",
       "       [0.58 , 0.723, 1.   ],\n",
       "       [0.732, 0.396, 1.   ],\n",
       "       [0.09 , 0.816, 1.   ],\n",
       "       [0.295, 0.746, 1.   ],\n",
       "       [0.747, 0.578, 1.   ],\n",
       "       [0.176, 0.045, 0.   ],\n",
       "       [0.132, 0.345, 0.   ],\n",
       "       [0.539, 0.064, 0.   ],\n",
       "       [0.971, 0.994, 1.   ],\n",
       "       [0.531, 0.935, 1.   ],\n",
       "       [0.913, 0.069, 1.   ],\n",
       "       [0.83 , 0.934, 1.   ],\n",
       "       [0.257, 0.032, 0.   ],\n",
       "       [0.825, 0.409, 1.   ],\n",
       "       [0.482, 0.769, 1.   ],\n",
       "       [0.806, 0.766, 1.   ],\n",
       "       [0.747, 0.978, 1.   ],\n",
       "       [0.339, 0.646, 1.   ],\n",
       "       [0.115, 0.42 , 0.   ],\n",
       "       [0.963, 0.993, 1.   ],\n",
       "       [0.141, 0.382, 0.   ],\n",
       "       [0.967, 0.87 , 1.   ],\n",
       "       [0.86 , 0.907, 1.   ],\n",
       "       [0.724, 0.376, 1.   ],\n",
       "       [0.98 , 0.683, 1.   ],\n",
       "       [0.967, 0.662, 1.   ],\n",
       "       [0.805, 0.539, 1.   ],\n",
       "       [0.366, 0.654, 1.   ],\n",
       "       [0.791, 0.348, 1.   ],\n",
       "       [0.014, 0.178, 0.   ],\n",
       "       [0.537, 0.537, 1.   ],\n",
       "       [0.455, 0.529, 1.   ],\n",
       "       [0.673, 0.728, 1.   ],\n",
       "       [0.672, 0.223, 0.   ],\n",
       "       [0.585, 0.003, 0.   ],\n",
       "       [0.822, 0.023, 1.   ],\n",
       "       [0.94 , 0.298, 1.   ],\n",
       "       [0.108, 0.673, 0.   ],\n",
       "       [0.234, 0.544, 1.   ],\n",
       "       [0.025, 0.532, 0.   ],\n",
       "       [0.884, 0.823, 1.   ],\n",
       "       [0.561, 0.248, 0.   ],\n",
       "       [0.915, 0.346, 1.   ],\n",
       "       [0.221, 0.276, 0.   ],\n",
       "       [0.063, 0.937, 1.   ],\n",
       "       [0.824, 0.725, 1.   ],\n",
       "       [0.909, 0.113, 1.   ],\n",
       "       [0.302, 0.809, 1.   ],\n",
       "       [0.408, 0.419, 1.   ],\n",
       "       [0.14 , 0.766, 0.   ],\n",
       "       [0.946, 0.884, 1.   ],\n",
       "       [0.304, 0.016, 0.   ],\n",
       "       [0.493, 0.206, 0.   ],\n",
       "       [0.097, 0.101, 0.   ],\n",
       "       [0.887, 0.034, 1.   ],\n",
       "       [0.136, 0.598, 0.   ],\n",
       "       [0.454, 0.703, 1.   ],\n",
       "       [0.67 , 0.049, 0.   ],\n",
       "       [0.743, 0.741, 1.   ],\n",
       "       [0.946, 0.402, 1.   ],\n",
       "       [0.419, 0.234, 0.   ],\n",
       "       [0.742, 0.217, 0.   ],\n",
       "       [0.155, 0.864, 1.   ],\n",
       "       [0.415, 0.056, 0.   ],\n",
       "       [0.099, 0.504, 0.   ],\n",
       "       [0.489, 0.289, 1.   ],\n",
       "       [0.408, 0.816, 1.   ],\n",
       "       [0.952, 0.732, 1.   ],\n",
       "       [0.033, 0.319, 0.   ],\n",
       "       [0.371, 0.598, 1.   ],\n",
       "       [0.443, 0.673, 1.   ],\n",
       "       [0.951, 0.321, 1.   ],\n",
       "       [0.855, 0.302, 1.   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Loading testData from csv, read and display and storing in testData\n",
    "import numpy as np\n",
    "testData = np.genfromtxt(\"/Users/panigrahirenuka/PythonPractice/JupyterNotebook/testData.csv\", delimiter=\",\",skip_header=1)\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get the third offset in the testData array and storing in testLabels\n",
    "testLabels= testData[:,2]\n",
    "testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.662, 0.525, 0.314, 0.173, 0.912, 0.342, 0.354, 0.772, 0.721,\n",
       "       0.643, 0.693, 0.61 , 0.192, 0.247, 0.558, 0.225, 0.973, 0.298,\n",
       "       0.289, 0.207, 0.705, 0.317, 0.349, 0.934, 0.795, 0.273, 0.122,\n",
       "       0.677, 0.38 , 0.98 , 0.818, 0.955, 0.805, 0.29 , 0.288, 0.714,\n",
       "       0.346, 0.442, 0.256, 0.479, 0.202, 0.539, 0.933, 0.696, 0.137,\n",
       "       0.616, 0.587, 0.242, 0.67 , 0.531, 0.638, 0.052, 0.413, 0.717,\n",
       "       0.101, 0.771, 0.005, 0.55 , 0.929, 0.407, 0.935, 0.878, 0.477,\n",
       "       0.199, 0.964, 0.321, 0.646, 0.908, 0.089, 0.574, 0.535, 0.723,\n",
       "       0.937, 0.913, 0.175, 0.882, 0.176, 0.92 , 0.997, 0.397, 0.495,\n",
       "       0.937, 0.962, 0.926, 0.877, 0.009, 0.568, 0.107, 0.983, 0.285,\n",
       "       0.989, 0.543, 0.494, 0.939, 0.851, 0.468, 0.193, 0.113, 0.162,\n",
       "       0.459, 0.257, 0.186, 0.737, 0.791, 0.568, 0.757, 0.175, 0.856,\n",
       "       0.897, 0.827, 0.515, 0.087, 0.669, 0.185, 0.141, 0.324, 0.248,\n",
       "       0.261, 0.236, 0.754, 0.954, 0.302, 0.723, 0.011, 0.654, 0.693,\n",
       "       0.062, 0.118, 0.307, 0.405, 0.503, 0.895, 0.704, 0.311, 0.117,\n",
       "       0.916, 0.295, 0.615, 0.219, 0.134, 0.153, 0.748, 0.606, 0.416,\n",
       "       0.549, 0.471, 0.538, 0.664, 0.218, 0.247, 0.755, 0.873, 0.082,\n",
       "       0.447, 0.704, 0.078, 0.564, 0.062, 0.548, 0.505, 0.573, 0.15 ,\n",
       "       0.328, 0.52 , 0.116, 0.205, 0.583, 0.091, 0.51 , 0.809, 0.453,\n",
       "       0.513, 0.457, 0.058, 0.462, 0.807, 0.723, 0.396, 0.816, 0.746,\n",
       "       0.578, 0.045, 0.345, 0.064, 0.994, 0.935, 0.069, 0.934, 0.032,\n",
       "       0.409, 0.769, 0.766, 0.978, 0.646, 0.42 , 0.993, 0.382, 0.87 ,\n",
       "       0.907, 0.376, 0.683, 0.662, 0.539, 0.654, 0.348, 0.178, 0.537,\n",
       "       0.529, 0.728, 0.223, 0.003, 0.023, 0.298, 0.673, 0.544, 0.532,\n",
       "       0.823, 0.248, 0.346, 0.276, 0.937, 0.725, 0.113, 0.809, 0.419,\n",
       "       0.766, 0.884, 0.016, 0.206, 0.101, 0.034, 0.598, 0.703, 0.049,\n",
       "       0.741, 0.402, 0.234, 0.217, 0.864, 0.056, 0.504, 0.289, 0.816,\n",
       "       0.732, 0.319, 0.598, 0.673, 0.321, 0.302])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### getting the first two rows of the testData and storing in testFeatures\n",
    "testFeatures= testData[:,1]\n",
    "testFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the DecisionTreeClassifier module \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a decision tree classifier object. \n",
    "## This is a raw tree, no data has been given to train it.\n",
    "## We are using all the default parameters for the ClassificationTree() constructor.\n",
    "## There are a large number of parameters you can give to the constructor, see documentation\n",
    "\n",
    "clf=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit the tree with training data\n",
    "## The output shows the default values of parameters used by the constructor\n",
    "## The split condition used is 'gini' \n",
    "\n",
    "clf.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now use the model to predict labels for test data:\n",
    "pred=clf.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(pred) ## These are the class labels the model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "### To calculate the accuracy of the model, compare how many test labels \n",
    "### correspond to predicted class labels \n",
    "print(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### You can see that all but one predicted label correspond to the test labels.\n",
    "### You can find the accuracy of the model as follows:\n",
    "sum(pred==testLabels)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StringIO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f6da8ffc28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### displaying a decision tree by using the graphviz and pydotplus in python by using the trainfeature,testfeatues, testlabels data as the size of the array is 3 rows, need to pass 3 attributes inside features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m export_graphviz(clf, out_file=dot_data,  \n\u001b[1;32m      5\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Attribute1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Attribute2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StringIO' is not defined"
     ]
    }
   ],
   "source": [
    "### displaying a decision tree by using the graphviz and pydotplus in python by using the trainfeature,testfeatues, testlabels data as the size of the array is 3 rows, need to pass 3 attributes inside features.\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True, feature_names=[\"Attribute1\", \"Attribute2\",\"Labels\"],\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
